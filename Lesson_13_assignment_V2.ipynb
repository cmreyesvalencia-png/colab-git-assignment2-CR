{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmreyesvalencia-png/colab-git-assignment2-CR/blob/main/Lesson_13_assignment_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Assignment 13: Generative AI Essentials**\n",
        "- **Course:** Data Analytics and Business Intelligence Analyst\n",
        "- **Institution:** Willis College\n",
        "- **Student Name:** Carlos Reyes\n",
        "- **Instructor:** Ratinder Rajpal\n",
        "- **Date:** 2025 Nov, 14"
      ],
      "metadata": {
        "id": "c4K-6uN95hUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**TASK 1: Dataset Preparation:**\n",
        "- **Dataset Choice:** Project Gutenberg (http://www.gutenberg.org/)\n",
        "\n",
        "**About Project Gutenberg**\n",
        "- Project Gutenberg is an online library of more than 75,000 free eBooks.\n",
        "\n",
        "- Michael Hart, founder of Project Gutenberg, invented eBooks in 1971 and his memory continues to inspire the creation of eBooks and related content today.\n",
        "\n",
        "- Since then, thousands of volunteers have digitized and diligently proofread the world’s literature. The entire Project Gutenberg collection is yours to enjoy.\n",
        "\n",
        "- All Project Gutenberg eBooks are completely free and always will be."
      ],
      "metadata": {
        "id": "h7tUTMlA5dPV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ480tfAXli5",
        "outputId": "48e4302c-1ced-418b-da92-7c26842ff565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "## Set up the environment\n",
        "!pip install transformers torch datasets\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "## Disable wandb completely\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TASK 2: Exploring Generative Pre-trained Transformers (GPTs):**\n",
        "- Model Architecture: load a pre-trained GPT-2 model and its associated tokenizer. The tokenizer is responsible for converting text into tokens that the model can understand.\n",
        "- Training\n"
      ],
      "metadata": {
        "id": "qgy42imf6g1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Load the pre-trained model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Add padding token\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365,
          "referenced_widgets": [
            "c84a9a3cfa604799bd5a0aad2921312e",
            "1130910e3ce54fac9d869075258ce2cf",
            "04a5033ee977496e8fc214eac6d08502",
            "89d06db010384e93bd7bfe757366f5bf",
            "748dcb9676cc4836b075f99c9244e146",
            "c439c1903e464fb0adf3e8351838fa22",
            "e24f69891da844758e8a12c21adc9615",
            "d971d6ac1a65411c8976728a75fa1b20",
            "a09fe9f261ef4b628aca764d2e0216a7",
            "4ef084735f2940c5ba6c3a0665f8e40f",
            "3931d8eb74c440918b75421c55b514da",
            "f703f4d3d45648528e755e764c7b6e8b",
            "bbd77b25cd694dea98cdb010249d91e4",
            "20a90c214d454470b2fa75705fe26021",
            "f2d9629670614d248be10ab27e82bbaf",
            "c28d3167578240c1aa17253c18041ca9",
            "cd9acc8bc6df455e9dc1b5b566fba51a",
            "73c8394781b8420e9fb11fda7ee1b54d",
            "2b2bfcfeed79455f99de79aeb41b30f4",
            "16bc44d0abfe449ca28454add656e452",
            "7b0f10194be34b4ab41e4ca90c2d0ca1",
            "ef1ccc09dcb8439280fd0919cbf0f227",
            "979f1dbe38d645e49afa13d52f711c39",
            "7ced07e92baf4a09aad5549d5263924b",
            "47b1667eca3d42eeb68a09f13f65a3c0",
            "1b52a613945842f88712741d3813dcb8",
            "373354828bfa4df5b7325f2eefaa3ccb",
            "2472af1452154cefb830713a961d50b4",
            "b713699340e14468b6d35a88ebf80f7d",
            "5d47abc8f2e1495bb96a7179a3c473bf",
            "ccbbf4186c944814b90a88445d66d6eb",
            "d427104351174550b4e8710dfd86b07b",
            "eec2a670a3e74c9ba48006d9b16f2bb2",
            "ed8ccb0359d640b7bd7cd98c12e9f847",
            "ddd8bff145d04412978e513b72864bec",
            "8aecf034cbaf4477a51bde240e215226",
            "189d320fd2c94b4e919240d907839081",
            "d9995e2778394c8395db7d96590c9aa6",
            "4683069865a741259e53a13491d9f4ab",
            "6cbbcb3308dc4e33a385de9c1d426305",
            "befd389ffe0645d0b7ee798cb4b0a297",
            "23c3e03b17924f8996ed9cfc1f45e840",
            "a1e32d208129460392975a38ca10bc11",
            "7475450d127d4467819c161a4679ca51",
            "834352d8db0f4d929e5f914099c967d9",
            "d385c1e934d04ff5a85add273866c40d",
            "29a5daa6b41c427eb6576744f4afefa4",
            "8a7b8c5c39ad4ba591d60bbe271983d7",
            "467623d1f14447c4a2a3e1ace8cd6a9e",
            "21c6bb5966984b1b905b18d303b1889d",
            "884782741e624374949bb9216cc2f6b5",
            "bb09ff5a4a9744ac8ec8e0d6647f34e3",
            "0ea6789bf24a4438880445af84cc7fd0",
            "eeb830dced69401aa3c91aab2ba3c159",
            "05462d53b82b4b03a744b946c8f0a2e0",
            "b4f21f6387ef49c2af61a90574f1f6fd",
            "a7f78142be6a45c18e9968e53862e395",
            "d8933f91bae14f749e15b868d16c4d14",
            "c84721258ed24a8880378d910eb5367b",
            "18833f8bc96045a0956e086b424d8ced",
            "9fb440a7fd92414389449411bb437095",
            "ee8497d3b25c44e39729a54c4d47e083",
            "523d7ada37ca4467b1f43fb0a7f4f650",
            "9b08809ef10c494289c274cb77c7abbc",
            "ac160b7a9a8f4648bd1ad189bd9813bb",
            "f79853d967714741926d847baf02a034",
            "f4c5ef9648384a8cb4050997174ede63",
            "37e7386ce9974e1fa1a14f19c0ec6884",
            "c1d6292bd2c54be4a0df631965644811",
            "ab92b24b983343d8ae647d794d431e6d",
            "6a575ae724d446eca46f078abaa26dd4",
            "5561067f3be548fbac88bd4fcaa675a0",
            "08b00795fd534bf38657d8b4d37e7b49",
            "b79003dc3c5c4f0185be3148596edc98",
            "9472be70bf604da2b55dabfc56fd820f",
            "2a22c2e9228b4a30bf50bdcbefbf5e62",
            "d65ddbc0e4214b4aaca887902e8350fe"
          ]
        },
        "id": "JiPnEpX1Lplp",
        "outputId": "a4883d35-16af-4740-f29f-312204542a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c84a9a3cfa604799bd5a0aad2921312e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f703f4d3d45648528e755e764c7b6e8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "979f1dbe38d645e49afa13d52f711c39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed8ccb0359d640b7bd7cd98c12e9f847"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "834352d8db0f4d929e5f914099c967d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4f21f6387ef49c2af61a90574f1f6fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4c5ef9648384a8cb4050997174ede63"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Load Project Gutenberg dataset\n",
        "print(\"Loading Project Gutenberg dataset...\")\n",
        "try:\n",
        "    # Load actual Project Gutenberg dataset\n",
        "    dataset = load_dataset(\"gutenberg\", split=\"train[:100]\")  # Using 100 examples\n",
        "    print(f\"Successfully loaded Project Gutenberg dataset with {len(dataset)} examples\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading Gutenberg: {e}\")\n",
        "    try:\n",
        "        # Alternative Gutenberg dataset\n",
        "        dataset = load_dataset(\"sedthh/gutenberg_english\", split=\"train[:100]\")\n",
        "        print(f\"Successfully loaded alternative Gutenberg dataset with {len(dataset)} examples\")\n",
        "    except Exception as e2:\n",
        "        print(f\"Error loading alternative: {e2}\")\n",
        "        # Fallback to literary texts\n",
        "        print(\"Using fallback literary dataset...\")\n",
        "        sample_texts = [\n",
        "            \"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\",\n",
        "            \"Call me Ishmael. Some years ago—never mind how long precisely—having little or no money in my purse, and nothing particular to interest me on shore.\",\n",
        "            \"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness.\",\n",
        "            \"Happy families are all alike; every unhappy family is unhappy in its own way.\",\n",
        "            \"You don't know about me without you have read a book by the name of The Adventures of Tom Sawyer; but that ain't no matter.\",\n",
        "            \"There was no possibility of taking a walk that day. We had been wandering, indeed, in the leafless shrubbery an hour in the morning.\",\n",
        "            \"Once upon a time and a very good time it was there was a moocow coming down along the road.\",\n",
        "            \"The sun did not shine. It was too wet to play. So we sat in the house. All that cold, cold, wet day.\",\n",
        "            \"In my younger and more vulnerable years my father gave me some advice that I've been turning over in my mind ever since.\",\n",
        "            \"It was a bright cold day in April, and the clocks were striking thirteen.\"\n",
        "        ]\n",
        "        dataset = Dataset.from_dict({\"text\": sample_texts * 10})\n",
        "        print(f\"Created fallback dataset with {len(dataset)} examples\")\n",
        "\n",
        "print(f\"Dataset columns: {dataset.column_names}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a9936b64f83d4b54a4db3e11c5a5f6dd",
            "1895852dac234813bd02fb0a7071721d",
            "d68344691daf45d99912e85f51899e33",
            "27434efc24d644858b526367486529ee",
            "7d927bca91154744923a10deddf56926",
            "2c14b510fded4abd9ef68a58a1649a2c",
            "9150cb566769444b8421feca29bb2d93",
            "322b60000c13407198c41b18c1122c47",
            "12ef2d6e5b474f8eb0a2dc10883ba447",
            "995161ffd1d14f3a9aca23ceaae2c067",
            "867aa3f785ab4d83b9a14353712fb139",
            "767463458e994a81854a66438b3bd51f",
            "92c9fa4bae13495eb3def137b5deb2b1",
            "7bf1e78d87a641269bca95dfae3c793c",
            "e29b196b0b5e45129398f468447c40e4",
            "c0cf8231ec5942a6b4fddb1b4e82e650",
            "2bce8463f4274c2a93cc2f5e34ffea7a",
            "5895cbc2566b40aaaa0813fad51d148d",
            "d98a720b96dc4dc699bc28a62901d2e2",
            "02d7d98140a34114ba9e8e03aaf99766",
            "faab75f5d5874e37b9c06b2622c7135e",
            "7cf35057112b4685aec3f086eb04d520",
            "0552b245f62d4d6cabcf6a60659409d4",
            "14ee32a2dc484048b80e889de6c85d0c",
            "12c535aef2f3445783e2aba6bfc4c522",
            "96570116268f4b5d8a06ca473d6cc589",
            "f129e9708c9a494e9453e4dd9ba2a354",
            "7cdd59aaa9ff49b8a5a342e5ce0f11ea",
            "3cc03de1349341bea6e1b60787fda6c6",
            "7aabb2ec021248b7aee011399f97aee5",
            "9470cd71f9ec4198a54fd2c549be39e5",
            "5af47adcd2634c62b1519f3af5f75aab",
            "edc81380e13f421cbe89e51bd301da39",
            "ec590b76f32d493abbe866df565d2094",
            "2e6c75b9cd334c6d95dbd933e0cae9ef",
            "77e6e9d0b907401c97aab57280734b4e",
            "4a7027fbae704cefb2746fe3704c4a0e",
            "7d1324f253f843dda25387459fadec1f",
            "abe33639b75944f1b3ff26f895d2077c",
            "a548712d22c0473ab78b3e87966da6e5",
            "24ee48d732844b518125be598fed83da",
            "5865f76de39641deb6eb493221af2c11",
            "12e0056fbf8b44aab01c17fb77810003",
            "6fb8f4a9734b465894fa44daee125e03",
            "b67637268a7d49e78cbcbeaa03bcec2d",
            "aedf30528a8e4fbda3c5a72b999f30db",
            "adaae06ccc20468dbc101c9a9d76c9fe",
            "199ee3e7627c40c386207dbddd58afe2",
            "73e477c0e37140f29d2d33679e2fbde7",
            "f21fac3a5447454e85e33e7d85d78ed1",
            "a72b02817f0a45bfabdefaf609a49e6f",
            "16a574531fa44d75ba3051e236ef2c69",
            "6048e323435a4a40880b5500e1b6aa6a",
            "b2cdab600f7347028aae5189e8e94f66",
            "fc3e82a26b784c8e90011b56848eb032",
            "870565b6c20443a89e648d197a339e09",
            "c9a7d2cb23e3437e9a033c343e15b132",
            "781fddc7021f4c28affa885539575948",
            "48864fdf021244cf9c918b1f3f09a72b",
            "7abc02bfcad6479b9c95f22d611d5aa5",
            "96870bd3b955461d8e9d2791ed7d0d37",
            "e74854c8b6d94cca90376eccd020b4bd",
            "938ccbb76cd24e6c871ce24930048679",
            "25e13c4c8e264b96848182efab387930",
            "5a2a4e41ee7949b8809c5a52e2e3e7c8",
            "f6f2683cedb14b0d80280e0c2345dc56",
            "9e73146ea3244e80b4a50e25b949f97e",
            "805c8766389449ada7af867f5a6dd466",
            "d812b5d77a2a4b518b5eb389feb4754d",
            "3ff27e1d667e4d0489ef3838ba742028",
            "24acd87ebe6c4a4382691060a28167f3",
            "e9ae4e485c0246ac84a8a410790a4964",
            "c952bc229a6e44dcb428aecd6ca8a6eb",
            "f02e19be650d467fa77bd46c3094d56f",
            "544e06d060824710a778b1781ad41c8f",
            "3968fd5ea116467cb01ef58296c026e5",
            "51fdc70df5ba4258a8dacaa0cb04fcd7",
            "304e936584d3476e9d7bd0995162cf23",
            "d6e3e98a9c3b4dbabbbf659c3f645f3e",
            "644e0b92c5ef4a26a4a3774e95182738",
            "65dad8aab7b34cc7a6b712de8d4ffb61",
            "bba600182ec844edb1d6cb43953d1b61",
            "931226838774425285eddacf31ce54da",
            "3842d4457d2a44aa9ae43dae9556e1f1",
            "8c127892f35d4948ac918195cfabe74e",
            "b7924a56c9e4410bb752f83ebbf6c086",
            "8a955442dfa44d7ba5fca1222abea7f6",
            "08f585c9fbcb47889d601cfa85952343",
            "566afab9b98d40cc8773686ad053e7ff",
            "fda7ad95838f46f2bb89b2f4548e701a",
            "5a279721630e4568ac155d2f8d72e153",
            "6c00d307ffa64976883d6ebb2b112c39",
            "aaa7e8731d894f7f9cc3e7a7d0393ba5",
            "238d05db624a416ea50432bfb617cccb",
            "655f67b541614e78aa54c847f1cca05b",
            "cdb3f987bde74d50b3b1752bd878923e",
            "2403878fff7c4a75b8c26f5e8ab6438c",
            "b74ebf7ed1ff410594b3107a33d40dcb",
            "8bc24e51364e4208ad3d48f8638ae425",
            "541511150e35460398a164d417aad428",
            "443c890e52794da685a0f4d1c5c6e640",
            "0e0c4d451f4546cb96fd65c5e0adab0e",
            "627dee9ca67d4596be3b1358e9368ca8",
            "4605cef5465c428480d301c238026df9",
            "bc023e0987d84e1bb3e1a9af3fa48ed8",
            "9720415b8c7c44878d788af9180a0609",
            "5441c492a4e2495ea263ece7eb4564b7",
            "a0340978bc564e1b830f21215aa9026e",
            "d81a361e04e44529a183cf0d7f75fe9a",
            "ed8837aab3504c8cba04e329a3a38c1d",
            "ff1496ee94e444d2ac3917bf5bf914ba",
            "6a19a62ef5e94dd49186f3ebc0abe504",
            "facf9a3f02ef4f6993459efb1dae5d94",
            "d748225c7b2c4b19a23b56d40f5710d4",
            "ec988a0310e64dcfbe1ad86fb2a6382d",
            "45bccee0e09c40cc95c69ffea77cd7cf",
            "9393fe09cdec48e59e762b3d795cb48d",
            "c00cf5165a91487c90e1158c86117a96",
            "62f0eb285f3442819e13ba75ba37cfc2",
            "eede9f04fd1a4b92a29fdaaa00668473",
            "a96c7f373c31409ea1ef248b4d5af899",
            "21e03d8923c44e39b453b089a3af9946",
            "57bc2fec86854b759b35d66f3487209a",
            "859d6947469149ebb56f9cf9f159cbc2",
            "84403b4eba48484786f8633acb96ab1e",
            "81d8a4a2bad64c2c8aba5a0bc938c6b5",
            "33bb8c2d4a934c508012dd9a125329ac",
            "40ec358b1eef4ec7921725a5f7685ab4",
            "7b479f1e278f4f029cd151499cf826be",
            "7b67f342d08d451b9825c60a10f9a110",
            "dfa30403859d43db9eea71edf4ecfe3f",
            "50e9191fbd8746dea83d59f079caaf9b",
            "da4475d05af74420a0a5cf8b88ec001d",
            "57e93f7f13654c33a5018acb44d614f3",
            "8d8674bd0f1d473e9194251e978353ac",
            "2ef97feeaeb44c9c989177484efb3e2c",
            "1cf43b2b91f445a783351545aa342003",
            "0ac1313b962540ff8e6d87ea44837b3c",
            "58c36757201c449d81bd39e374a8f476",
            "a5d1f3e57d9a4ec4b39e54371468dbf9",
            "fe9f83f301cc4d65954f0f452d8836a6",
            "1a5ff1828f9e40e088edd6bd5cf52c62",
            "63a830b961de4f339ecd72c5e04eff91",
            "d438c69c93e849e9ad11ec7e4d05213c",
            "8939b6a7666941c28c15d815f540613d",
            "0a7e7007a28449d48b7d825d78aef1c3",
            "d9da2e83e65542a098b3eb92ec4d706d",
            "76194091153c42d0b69dbc02cb462d1e",
            "e5adc71276e748f298ec21ad025fad09",
            "8f9a3de4c79f4d8d95e85ea54c60713b",
            "9b9f5dd12cd04f0180a9ccb77d02f9fa",
            "73294678520041d2b5b502c4fb561c34",
            "36e642a5b61846ea8cdaeda81df69272",
            "836052c2eb4e439aad4cfe917d7f49a5",
            "f942bf57c44d4905977feeb6c9e068d3",
            "017b834c5b4f466d88405c07fea00ed7",
            "d15ec67fe1944739bdb32ef3a7d7c691",
            "51030378f85747b587762da492b496e1",
            "078007eb64414b82b7c510ebc615fa07",
            "b01d2544f0554274931e2d8290cc987e",
            "44d518fbae184872bd5c3b0cceab6d52",
            "0a72b2b06c7341b3a6bed008610a16c6",
            "41e113c2ec18467289ecb8bf36e093aa",
            "f2a09b2dd61c488a918e34f6e8e0a5b3",
            "4c0a9654df4a4f738abd2dab10a10ef8",
            "3e413a4b0ce84382bbf77da3f4ef236a",
            "a857c8d1d5f845a7980c0c82c8677132",
            "cf56a229e4d9448a9de208968f0de734",
            "afb6db853494454db2859b8da17f3ad0",
            "149487b266f046f3a7911f60258f354e",
            "f71aed63be1c40cc90b9c9f143bdbe28",
            "e679ae26e3e140a6af20eb3c7a773311",
            "9b839eec9d0343d3b121bf80367516a3",
            "1349be01236f4ec48e0b360f8775214a",
            "80b0ec1ff7404a3e9181bf06818bb5c2",
            "08e92f948bf14203b9c5f57369423437",
            "2d974653c8584a06ac4626aa728cc371",
            "7f57dcbbeac74889ada7e2c3914e718f",
            "2d140d5a02ff4fcb83aaa2392dd2d7c6",
            "486e84b18778453f89b0fc130717ae1f",
            "71c70f8c39044d82a5f951ba3279872e",
            "73670459fefc47b8a461f13b46c48a43",
            "23f54f4035ac4bc98b1df8f3c36d8402",
            "fd8f86dceec14fbf8814ad5d416ad68a",
            "33a5da854eb04245b82c9d25f08c6923",
            "d36ce3a09a71493caf8b7d6b6ba1b739",
            "3df59b9099f74d648831258e968305f9",
            "70d24a64daf04bc8a52cd15023e3e20c",
            "0c6d460d25d04b9faa220cbd8f12f3b9",
            "fb22cf856b524509b39d57e534d0954d",
            "8d0766d7928145028f56fec9ce063c23",
            "72e9745d725549899693d61efa58beef",
            "14371d7899804f31a77a94e4e851ffc0",
            "2eb3c40eb8cc4232b866812e5b241221",
            "922106e1b8584af7953872a30d89dca8",
            "f0f3b76790fa4a72b473de62ca2ec6ce",
            "f4d3205a797c4264bb193d2d21f5203b",
            "c51310220519448d8637de97abac6f5a",
            "1f91c9b2b4694aa1b14d14ab22328a4b",
            "5941bcc3505c482eb41a555adaaab755",
            "0c9ab9db535c4c71b4d84373a77209f0",
            "c2d5e177443d4e31b7147f7afddf0bb5",
            "3baaa9daf9df4c428cb9a009eba8882a",
            "ef79f5339b354555921fbf12a6f0a023",
            "1b31d4d3e4fd4e22a4d49a51ee70bfd2",
            "f6be3d4dadb24d49a2911418030fb9fd",
            "9631d814521b4fc082e9be6a83778e81",
            "710b9ff216d7430aa4606d20a0c00890",
            "a454521540264d8eb95bcb44bd080ea0",
            "0cd1fd4b09da48c4b4deabeb065c89dc",
            "e7b8b2173fec4f25b8afbe9d3af13a8c",
            "7ff282337f934c079961ed02e7151433",
            "90932edd065b41d89dc7067095d5eeb0",
            "6c26f72d8aaf40e2bf792dcf2a5c2deb",
            "edb0aec3084a4f9f9702a6120dfc770d",
            "26d300605a3e4a699f276ce366983056",
            "9e8e7424b5d245ba967decd67c66aa09",
            "c222797bb5b74db2b5649d4cb454f48a",
            "3aa76fdd55c34b4bbf7385744eaca101",
            "25963458f4d84179b1e4fd3bfd8ae8a8",
            "6b1ff6ec4a504aa6bccb760c701abedd",
            "098245df8fab4cf1ac19f35144dda7d7",
            "3621810b0e5243b8b998940ef7866e47",
            "aa6a51d640174f3eb3d0997e0e4346ef",
            "936f4de199304d58b5e14ee09bba8029",
            "bfb2afca88f343f4b59c80e370fd846b",
            "689f73b76f974385aa850ddf50b563fa",
            "63389af0ff0d46868f7dcc4701faaa05",
            "7663dbc86c54441eaf2c89130bae865d",
            "cf992a82648548868b66962e11220587",
            "5af3eb75af5e47c094e11e0ce1019e7e",
            "1fae03cbde4a4819b076833afd4d3e1e",
            "b8ef9f351ead43749cefbb0851ab61b9",
            "6f5717e7ef8d4db7be4f91f75bbcdcbd",
            "fd51ef513de14211ae3468ab3b84884d",
            "777c5dc6c624493db2beb9a53a4ad108",
            "485774cef320473f9a81d5f70e0650e4",
            "d2caac54b0cb430382935a36f4c45460",
            "2067382df98f434a8950c56da28ef7bd",
            "6d5b2334d51a4acb915b49aea20954c5",
            "f3de8618cebc4bf6a8a77798dcb50cd4",
            "342c589884e24f4e886761842b032c7a",
            "21594387069b407cae74517f70f86fd4",
            "cce61a50cf3d436ca5f0539bf19f4991",
            "2e052a0f55a642f29c4433e01200e2f1",
            "03253c54e4854032bdca0991dcb05d82",
            "6bc21d7aa49043538245a3bfad561be8",
            "242b3744773341afbdb20986270a91ec",
            "8c2ff92a6e0c4d098244325baf671620",
            "87e1d8622bce4f98b1ce81a5634713ae",
            "d43881745a8c462ebabbabbb1d6ebbcb",
            "31143196798544319f0d9e4bdde18b0e",
            "7f22881531424838b52c758a79138378",
            "2878afefe0ea4fc884f3118ba6168230",
            "89adae8122894772a425c0eff288c060",
            "48ba180ba05f4c98b582966b3c47ccec",
            "962201e742894307bbf36a1704cadfd4",
            "a02c195d07484d8585480d3bb2420cf3",
            "2546f08d0ab64208b7f3810da55ac066",
            "7b5fbd47ccc743029e66812878f1b1b9",
            "478667b83c494ddc88cd2ba19938668d",
            "47350949067d440b958d9a99704656f3",
            "ff81f398230f402c940ecd85defab6f2",
            "fc554da45f58463bb2b5a7955b3500c4",
            "b4de8836c6754748b128b07f94c59d52",
            "ff6cd014bdd24064b61e0b49fb5221a4",
            "5ae959f803494c93af3c19cefa569e02",
            "ed96212bb68e41aca075c1b882540d06",
            "59f41a55fb3e45759d6d5739e38f286a",
            "a438d19860e44501a84473b6b653ccd0",
            "c73c9507a49b4d2fba4bdec9e6eedd6a",
            "d8c0904ec9714c7694a62fb1f5b85e47",
            "28213e6d7c7e4a5b91ec71b71a357f5f",
            "4afcf59cedb34d1a928e18c8cced2f55",
            "a59fbcaae5cb45eaacaad95d8969f6cd",
            "67fa1323c76f4fa9808b46121447e5f6",
            "bbac592bac3d4dd8b5015589244226d6",
            "190ce9cdaee847fe9ca0f07ad7f26997",
            "bcedd98fbd2146e4bf2a303d70d0d885",
            "bc89944fbd2b438f91f89fa881366d95",
            "48f9b3338b8e442f942366fb896e13f2",
            "209d99ae5ffc4fbc975358bca3f0d671",
            "72681c381a7c4598a4449f12eb365bb5",
            "4e6efbcf94874bbeb2e067e9d53bb455",
            "a82c2f6b15674f0f8c48ca51e9b8b9b2",
            "a99428fc09074e31ad97d7c21d2b2112",
            "11fcfd3385ba448b8771d6e47b558284",
            "9eb5be92405c4aa3ac68318204a6acaa",
            "abfe3991e72443ffa9a8c1fba81b8080",
            "d36a3a908e44400c8824831d51ab1070",
            "f4d65cc757874a9eb352e72c7eb98b8b",
            "c981ee6e4f674bb29d20f77d637c4617",
            "052c1c9a27944ee48dda6b0bd3075f96",
            "1b130c4f283448bd83f50f2d42f47441",
            "7b8fecd14a5249c2b14fb51f5256a5e2",
            "dc8b1de9604a4238813996065a100c61",
            "8fd4545bd90548c7b2070695c0c85a80",
            "ac1863a7d2db4ad7a9a03c42581c4a89",
            "bafd4b6a096a4aae9269044b0792415c",
            "b64b35ff2a41495fa6d7416e7adf5a53",
            "4bd426a7bdf14cd1bb7ffa4563d4047e",
            "2b684afe895e4abdbc43be56104e0f43",
            "03249f191f2f4e8bb6795cdf513a731b",
            "c2c48752d9fa4edfa7101ade207455c8",
            "3e66b6ec0a5742ffbf784dc8259eb1bf",
            "f4fcb73bda9c4af6ae2fbf946b00012f",
            "4dedd3842f8b4c59a6d4c97259415e64",
            "c2508e06adf84c28a818e94186cf38cf",
            "260a45e93f0c430c9ea86d44a2249e90",
            "7eb0e1acef144b12a482978a486de2d6",
            "3df68005e55249db8aabef9b6816033f",
            "ac4c682259ff4dde9ea185d462d821a1",
            "0ffe0f7aff28468f9e689298fa5bdf5d",
            "37762a71443c4d1389f841223127ba2b",
            "b084501181ae439e951b485036e262da",
            "14bccf73164941aa85e8e10f92b79764",
            "80ad47f9149c4e7191ad7fbbaa6c96c9",
            "40b0a4fee8ea412fa32bef8c234358af",
            "3d9a9692a3284d19b858bc6cb71b0f81",
            "636d801186864d33a98999e161c9ab16",
            "6b02f91fae1c477b904ad0b45986ddf0",
            "e5989decdcb04174afe0e799396999ee",
            "ae9dd9d52b1d45c2b790b9e827a43665",
            "5df427d489484dc6afbebf45694970e1",
            "83e252c27a9043a48afa387f8611e1d9",
            "d677f342a73d4c0fb447d62c070b62ba",
            "c2f9e677fdfc4a4281075b2e6c71585e",
            "2b1021d9411e4a86b70bd81c7f3867bb",
            "de4d559c75d5403b9b571a065dbbf095",
            "843fc91abbd94c019b3871f5457d64c3",
            "fce665a8e8fb44558815b3f4ecf603ed",
            "62d70d321b6e4c3ea494faa567660b22",
            "1b990f5bae964faa968a3cd574522992",
            "cc1de3545fb344b4951fbce7364db84f",
            "af1fa16a93fc407abd31ab71f9a6a037",
            "313c09ea104247098b560a66092893ad",
            "f9b1835f1d054a5181fb9c67eaaedcaf",
            "a1051e152ae34c9b8b852d5233cfe48d",
            "0f5810e9eb7240a4a56fd9b08baa0201",
            "b321078ce8044bf18191f000d69ae20c",
            "3ae190a747364974a570f73ff192adbf",
            "a112934475fd4764bcedb974437314da",
            "fa8aface024b4be79e9b2e295dfb86cd",
            "870a046f4c4b428fbc9f5343e59c6bfb",
            "674fd7f668f24661b403223c526690b8",
            "2be3a821bf9d4316a2a0f3e091167c6c",
            "52aec513bdca47cf92e0e8aa0cb4ec89",
            "0f9bc0ed26034b2bbc9e1bd039369330",
            "2b3761cd90b14e65a1f41bfaa918e747",
            "27f677395f144cebacc88985266d1330",
            "d59cf4c2649e4e9089ab0826c638225f",
            "4b50b7dcff6a4e6a8ccecad6d959d08e",
            "c20aee37037a4ccc8ddcd5e7cc3aecd0",
            "e947f1365b434507b409897b652b2469",
            "edbd5f9c86934c8ca1dc62ab91485d5b",
            "e68e4d1c567a4642a18b30a73cbcbe3a",
            "fddc877928074615ab9f20f74a38862d",
            "7c8a20bd688e4d9897c2be0bcd2b31cc",
            "49c671c390264d19977de81d3239e851",
            "03dc8bd735ca46c8bbf6e6db965b3074",
            "70b872955a7f4027b01bd5c61728caaa",
            "947ee55126e043469769248fe56f744d",
            "fd109510d01347ffbed28313b6934e8b",
            "6883b366666d4b639ae9a11b39f69f50",
            "c9760ee7998e4ee28f27eebdc10e8424",
            "d42749e6ee1d4d4c9908d3cf88f9d8af",
            "57d73b1a2fc842dbae67b36c8c190a7e",
            "962cd52ab0a84a92aeec15a97ea28996",
            "9038d365c92f4defb9aed08a9deaa95b",
            "a8c70900be5848baae3a7a1fb8fecfc6",
            "dc474a6133b3407c85ba9e6649d9b137",
            "a437a86cc79c4226b78930bc7bd38541",
            "9f80e78ddc064f9c96339aa73af16554",
            "2527dc8586ca4868848ce6d2bbb2656a",
            "47938dff29264a44b205e4ba3676291c",
            "7b11d97134db4e15b88e8ec72e5ef4fb",
            "67dbce6399ca494cab298a68b0ce55ef",
            "fa9abdf3329a4ceca767496a73b7541a",
            "0f1e141fedad4941b6c31c069cd626e8",
            "e3ab4eec11e44ee1a2f43b67ec811183",
            "41b7c7c8ea9848a5adb21e0dbb09d4c2",
            "04320b40caa24f0ca7464f5294165814",
            "81111aee9ec04cdfad445c77b6fb98df",
            "47db2096439d49bf8e542883eef9320f",
            "5fc5ca8a33f34a199835e4daa72d1992",
            "550cb88dc0bf4cfe979adb5962acdf23",
            "cfe6fca092ba4111a8b78a0ffd32a9f5",
            "0e2edf247b9745469358ce11cc55f3af",
            "6d83100fe96f4063a37bff540aaee5c7",
            "89643189c2a7434fa0b3f98f2ccdb5ab",
            "7d1fc7c51d3f427ab0455b895c8717ed",
            "33eb97b4d78e4eedbf07119c23512244",
            "46296c3b9c904da3a92f923b6da93db2",
            "68dcd5219901427ead82a1a44551008c",
            "9b08e9f309204a3793c3bb2d3a169fde",
            "4f00197fa9a8454fa81d2dbf2369e448",
            "cf0ff37b51604b0ea749a9acc5bede34",
            "707cbcbe0e1c40329414550d78988c7e",
            "b819424d8a9642218a80c77862d4310a",
            "88064873bf6748e29f5ce761a5418d2f",
            "7521ca47c12b4e0195506dbb41e8cce3",
            "1705cc3ffbd241aba2f3b0db14304ac7",
            "b1ebf136aab541cfbd5bc2c59f2086ad",
            "42ff12d4a6a24d21ac4febbd3de52ac9",
            "e0cb2deaf0eb41efa550dd4ef225153a",
            "a3d5b695e0794a4c955aee2f31e62861",
            "d5f6474f73f9455a806a8b8698222218",
            "022a0453e28544dc982bdd154b27a46a",
            "0c144fcf948a440796bd74e63cbea24c",
            "1fc467aea93f48d3b14a84c7a2e799e9",
            "e1c5e6f840c54680aa30099c53f992d2",
            "84cfae636c264b788ba0d26d7d68fd6f",
            "1cd44aa2014e4ee5a46a3eddb4b787c9",
            "89e2be67eaa0462ab1737da213672dbb",
            "f6847bdf902f4ef68a093e06cdf03c50",
            "c06f5eaf0b604449af502b5d00d305a0",
            "7efd6712c3554c2aaa9f3d44d2d6926a",
            "4f1a6b734ded4001b4aebbf8ac3e7034",
            "8dccb1d01f8743e3b213ab054130b8f0",
            "14961a1108dd4406a506bdcedbcffd5a",
            "77c645100b5c4717885f54f4a2eac46a",
            "3448ca331d0f4a2fb2990d462e7570c3",
            "4d51ce1cefd54bc4814125e5f3451c82",
            "c54401f937b247a2b8160c0f640d12b7",
            "a40ba73abcd24ee0af0c878893a622be",
            "acb678ae5bd74fc5a26b6aa71fa4d254",
            "498cbc0912064e9b9d2632b3bc8d0523",
            "e0e34d021e044434bb3a3cb3f556c1b7",
            "9f6ed846bed64b31b7f5aa30ee1df113",
            "3dbdd1f7e2bf471a9eed355abc567d21",
            "1ee3e657a7894a6895cf82e26602b0f6",
            "2d8ba5c1e6364eee9bbaf4ebdaa03ddd",
            "6bdd6313cb574e3a92761e4c647a60fb",
            "fe60a8ab6b4d476d9b6e9439af4ee6a5",
            "84fc635ee25746c3824b8e4660924272",
            "4d51a298a84f4b50b74e229b6b58900d",
            "a9d1c75fbdb14e68aaac575baa94517d",
            "203f4e7494a04d57a47dcc743c6fcef7",
            "9eea793dc6714b1588f5baec3fa93696",
            "cabfbc17f48440c1a4b7ee37b5854dca",
            "4303705c97ed47d4aed564cdc8c0e783",
            "2b400419e04041b28f3296439f35bbc9",
            "7da56e8e2ba04a37b8c75734274a831e",
            "00858b0b51e3422ca9724c0245405825",
            "f00e135c73994eeeab7ffd744debd4e6",
            "bfc7bb1c7e37491a9f248734125649ae",
            "88298341d56742bcb2a25b004009ec9d",
            "f91c89c6da45451abe20e19c2eb41f71",
            "3fa86d8f29c04baf98c5745fea59bba7",
            "c47abda3a1a24817a6595a7ea4a940ca",
            "d984ab249b344492a75a77f1b19f2b11"
          ]
        },
        "id": "z6BP1UtWSXR5",
        "outputId": "35dc3b97-1ea6-44ab-b21d-2b396b74bd7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Project Gutenberg dataset...\n",
            "Error loading Gutenberg: Dataset 'gutenberg' doesn't exist on the Hub or cannot be accessed.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9936b64f83d4b54a4db3e11c5a5f6dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/37 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "767463458e994a81854a66438b3bd51f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0/37 [00:00<?, ?files/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0552b245f62d4d6cabcf6a60659409d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00037-f5fce855b93d2d(…):   0%|          | 0.00/336M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec590b76f32d493abbe866df565d2094"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00001-of-00037-9f227d74fc154c(…):   0%|          | 0.00/343M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b67637268a7d49e78cbcbeaa03bcec2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00002-of-00037-bea1b37be317e1(…):   0%|          | 0.00/349M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "870565b6c20443a89e648d197a339e09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00003-of-00037-04e66b9f813765(…):   0%|          | 0.00/306M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e73146ea3244e80b4a50e25b949f97e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00004-of-00037-f6c07110175b63(…):   0%|          | 0.00/260M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "304e936584d3476e9d7bd0995162cf23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00005-of-00037-ba4d58fedca000(…):   0%|          | 0.00/297M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "566afab9b98d40cc8773686ad053e7ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00006-of-00037-7b789f01c0c22b(…):   0%|          | 0.00/285M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "541511150e35460398a164d417aad428"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00007-of-00037-6bbe2fa08aa331(…):   0%|          | 0.00/269M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff1496ee94e444d2ac3917bf5bf914ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00008-of-00037-033888fa3848dd(…):   0%|          | 0.00/283M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21e03d8923c44e39b453b089a3af9946"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00009-of-00037-8b793451f276e5(…):   0%|          | 0.00/293M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da4475d05af74420a0a5cf8b88ec001d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00010-of-00037-316f04ddc46599(…):   0%|          | 0.00/195M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d438c69c93e849e9ad11ec7e4d05213c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00011-of-00037-099dbd5b328cda(…):   0%|          | 0.00/249M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f942bf57c44d4905977feeb6c9e068d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00012-of-00037-4f4740996a0472(…):   0%|          | 0.00/251M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e413a4b0ce84382bbf77da3f4ef236a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00013-of-00037-db4f861f78cdda(…):   0%|          | 0.00/274M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d974653c8584a06ac4626aa728cc371"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00014-of-00037-be958e07745007(…):   0%|          | 0.00/246M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70d24a64daf04bc8a52cd15023e3e20c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00015-of-00037-3e422fddf4a02b(…):   0%|          | 0.00/235M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f91c9b2b4694aa1b14d14ab22328a4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00016-of-00037-45b3a0df26130c(…):   0%|          | 0.00/289M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0cd1fd4b09da48c4b4deabeb065c89dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00017-of-00037-116da6a2fc3d46(…):   0%|          | 0.00/298M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b1ff6ec4a504aa6bccb760c701abedd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00018-of-00037-3669e1517089c7(…):   0%|          | 0.00/282M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fae03cbde4a4819b076833afd4d3e1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00019-of-00037-8b2f1a8fec0a21(…):   0%|          | 0.00/365M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21594387069b407cae74517f70f86fd4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00020-of-00037-3d99168fa7b0ed(…):   0%|          | 0.00/348M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2878afefe0ea4fc884f3118ba6168230"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00021-of-00037-8ab80417e78ceb(…):   0%|          | 0.00/342M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4de8836c6754748b128b07f94c59d52"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00022-of-00037-0944fc61fb4ac3(…):   0%|          | 0.00/348M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67fa1323c76f4fa9808b46121447e5f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00023-of-00037-d7895637ed3af5(…):   0%|          | 0.00/333M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11fcfd3385ba448b8771d6e47b558284"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00024-of-00037-09bea13a1df159(…):   0%|          | 0.00/328M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac1863a7d2db4ad7a9a03c42581c4a89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00025-of-00037-473104aa5efb2f(…):   0%|          | 0.00/303M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "260a45e93f0c430c9ea86d44a2249e90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00026-of-00037-4b7511a415a200(…):   0%|          | 0.00/286M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "636d801186864d33a98999e161c9ab16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00027-of-00037-66093127ec6001(…):   0%|          | 0.00/312M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fce665a8e8fb44558815b3f4ecf603ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00028-of-00037-fe9e77c7977cfb(…):   0%|          | 0.00/340M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a112934475fd4764bcedb974437314da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00029-of-00037-43de64be3239f1(…):   0%|          | 0.00/329M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c20aee37037a4ccc8ddcd5e7cc3aecd0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00030-of-00037-ff9b258680737e(…):   0%|          | 0.00/286M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6883b366666d4b639ae9a11b39f69f50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00031-of-00037-73093f2c2aca90(…):   0%|          | 0.00/270M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47938dff29264a44b205e4ba3676291c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00032-of-00037-1fafc6475b8daf(…):   0%|          | 0.00/244M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "550cb88dc0bf4cfe979adb5962acdf23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00033-of-00037-9427a3c9a92092(…):   0%|          | 0.00/219M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf0ff37b51604b0ea749a9acc5bede34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00034-of-00037-a50c4691ce7976(…):   0%|          | 0.00/232M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "022a0453e28544dc982bdd154b27a46a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00035-of-00037-fbd49649c75593(…):   0%|          | 0.00/264M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8dccb1d01f8743e3b213ab054130b8f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00036-of-00037-f95604828486cc(…):   0%|          | 0.00/259M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3dbdd1f7e2bf471a9eed355abc567d21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/48284 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4303705c97ed47d4aed564cdc8c0e783"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded alternative Gutenberg dataset with 100 examples\n",
            "Dataset columns: ['TEXT', 'SOURCE', 'METADATA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize\n",
        "def tokenize_function(examples):\n",
        "    # Find the correct text column\n",
        "    text_key = 'text'\n",
        "    if 'text' not in examples and 'TEXT' in examples:\n",
        "        text_key = 'TEXT'\n",
        "    elif 'text' not in examples and 'content' in examples:\n",
        "        text_key = 'content'\n",
        "    elif 'text' not in examples and len(examples) > 0:\n",
        "        # Use first string column\n",
        "        for key, value in examples.items():\n",
        "            if isinstance(value[0], str):\n",
        "                text_key = key\n",
        "                break\n",
        "\n",
        "    return tokenizer(\n",
        "        examples[text_key],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "print(\"Tokenizing dataset...\")\n",
        "tokenized_dataset = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    batch_size=16,\n",
        "    remove_columns=dataset.column_names\n",
        ")\n",
        "\n",
        "print(f\"Tokenized dataset ready with {len(tokenized_dataset)} examples\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "901a001de5ce4a8fa0606f63c357c58e",
            "caf63df76d8545efbcb3be3036570560",
            "f9521e58f8d343769767290fe8b4baf8",
            "25e171eed69c49dd8dfda55e07592dbe",
            "16bdbe5ecadf4a44af85dceaedb283a1",
            "13564ec680f34d5a8698b3b4861c5b54",
            "4c87ed5308a341a6894e2cbeca47f407",
            "edeaf7a71b7b4aeaa481015048492cb9",
            "eb7f1018b47946048dd81acaa6af5062",
            "8ca792e541584e979f5a43b1366a81b9",
            "6ca84e23f19b4839bf8a91e4be4ff1ac"
          ]
        },
        "id": "OEGeGU0jXQtZ",
        "outputId": "19d1ae73-5a95-4e10-e41b-9889e77c4a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "901a001de5ce4a8fa0606f63c357c58e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized dataset ready with 100 examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training setup-Training model on Project Gutenberg dataset\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2-gutenberg-trained\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=4,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        "    remove_unused_columns=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Create a custom data collator for language modeling\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "## Train the model\n",
        "print(\"Training model on Project Gutenberg dataset...\")\n",
        "trainer.train()\n",
        "\n",
        "## Save the trained model\n",
        "trainer.save_model()\n",
        "tokenizer.save_pretrained(\"./gpt2-gutenberg-trained\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "bHyvPb-SLvOQ",
        "outputId": "97560ce0-68fc-4989-a995-7c10a2a71527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model on Project Gutenberg dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 04:01, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./gpt2-gutenberg-trained/tokenizer_config.json',\n",
              " './gpt2-gutenberg-trained/special_tokens_map.json',\n",
              " './gpt2-gutenberg-trained/vocab.json',\n",
              " './gpt2-gutenberg-trained/merges.txt',\n",
              " './gpt2-gutenberg-trained/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Load the trained model for generation\n",
        "trained_model = GPT2LMHeadModel.from_pretrained(\"./gpt2-gutenberg-trained\")\n",
        "trained_tokenizer = GPT2Tokenizer.from_pretrained(\"./gpt2-gutenberg-trained\")"
      ],
      "metadata": {
        "id": "LUL1W9eKMaPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function\n",
        "# To generate a text with different parameters\n",
        "\n",
        "def generate_text(prompt, max_length=100, temperature=1.0, top_k=50, top_p=0.95):\n",
        "    input_ids = trained_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    output = trained_model.generate(\n",
        "        input_ids,\n",
        "        max_length=max_length,\n",
        "        temperature=temperature,\n",
        "        top_k=top_k,\n",
        "        top_p=top_p,\n",
        "        do_sample=True,\n",
        "        num_return_sequences=1,\n",
        "        pad_token_id=trained_tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    generated_text = trained_tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "fe5ptgkbMtud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TASK 3: Application Demonstration:**\n",
        "- Describe and implement examples demonstrating a content creation application using the trained model."
      ],
      "metadata": {
        "id": "xutdqAme7y91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Practical demonstration: Content Creation Application\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CONTENT CREATION APPLICATION DEMONSTRATION\")\n",
        "print(\"Trained on Project Gutenberg Dataset\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Exercise 1: Basic Text Generation\n",
        "print(\"Exercise 1: Basic Text Generation\")\n",
        "prompt1 = \"Why love is important?\"\n",
        "print(f\"Prompt: {prompt1}\")\n",
        "print(f\"Generated: {generate_text(prompt1)}\")\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qgwco11YMxcf",
        "outputId": "998b4b1b-faa3-4d55-e42b-71a1edb8b04c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CONTENT CREATION APPLICATION DEMONSTRATION\n",
            "Trained on Project Gutenberg Dataset\n",
            "============================================================\n",
            "Exercise 1: Basic Text Generation\n",
            "Prompt: Why love is important?\n",
            "Generated: Why love is important? The world was created for its men, so it is necessary that those who hold power should feel that love, and that they should aspire to it. The world is made up of men; if we fail to love one another we risk their safety and glory. I ask the world to look to us with open eyes, and to show that we are more than friends; that we know we are in danger and that we owe every man, and every woman, and every child\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise 2: Controlling Output Length\n",
        "print(\"Exercise 2: Controlling Output Length\")\n",
        "prompt2 = \"In the beach\"\n",
        "print(f\"Prompt: {prompt2}\")\n",
        "print(\"Short version (max_length=50):\")\n",
        "print(generate_text(prompt2, max_length=50))\n",
        "print(\"\\nLong version (max_length=200):\")\n",
        "print(generate_text(prompt2, max_length=200))\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr4T9j8cMz8x",
        "outputId": "56fe90d8-40c4-4ce0-e147-9afa5d27ff46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exercise 2: Controlling Output Length\n",
            "Prompt: In the beach\n",
            "Short version (max_length=50):\n",
            "In the beach were a few men:\n",
            "A young man in his late thirties,\n",
            "A short boy, with an older brother,\n",
            "Three young women, dressed in full uniform,\n",
            "A nurse, and five young children,\n",
            "Among\n",
            "\n",
            "Long version (max_length=200):\n",
            "In the beach he says it felt like 'my body is going to explode.'\" (Courtesy of Chris Gentry)\n",
            "\n",
            "After a year's worth of fishing, at last he heard the voice from the sea in his head. The night that followed it was a terrible day. \"It was a storm in the water, and at that time I was not yet strong enough to stay in my boat,\" he says. \"I came on shore a little later to try and convince myself that I could never be stronger than I am now.\" He got ashore in a little town at the southwest shore of Florida. In the harbor the man said something similar to a sailor, who was trying to calm the waters: \"When you stand down on your deck you will be the destroyer of the sea.\" Gentry called out for the man: \"I am very proud, and it was my duty to help you.\" And it is the voice that would speak to the destroyer that Gentry remembers from his youth\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 3: Adjusting Temperature\n",
        "print(\"Exercise 3: Adjusting Temperature\")\n",
        "prompt3 = \"In the depths of the forest\"\n",
        "print(f\"Prompt: {prompt3}\")\n",
        "print(\"Low temperature (0.3) - More deterministic:\")\n",
        "print(generate_text(prompt3, temperature=0.3))\n",
        "print(\"\\nMedium temperature (1.0) - Balanced:\")\n",
        "print(generate_text(prompt3, temperature=1.0))\n",
        "print(\"\\nHigh temperature (1.5) - More creative:\")\n",
        "print(generate_text(prompt3, temperature=1.5))\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9OSV5VbM2cK",
        "outputId": "ad90157e-d2e9-449d-8894-da424b96c979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exercise 3: Adjusting Temperature\n",
            "Prompt: In the depths of the forest\n",
            "Low temperature (0.3) - More deterministic:\n",
            "In the depths of the forest, the wind blows, and the wind blows.\n",
            "\n",
            "The wind blows, and the wind blows.\n",
            "\n",
            "The wind blows, and the wind blows.\n",
            "\n",
            "The wind blows, and the wind blows.\n",
            "\n",
            "The wind blows, and the wind blows.\n",
            "\n",
            "The wind blows, and the wind blows.\n",
            "\n",
            "The wind blows, and the wind blows.\n",
            "\n",
            "The wind blows, and the wind blows.\n",
            "\n",
            "The wind blows, and\n",
            "\n",
            "Medium temperature (1.0) - Balanced:\n",
            "In the depths of the forest at night, she was sitting quietly beneath the fire, waiting for an answer from the enemy—a voice she could not place. In that instant, the battle had begun. She thought in a trance, a trance that might be described as like listening to a song. It would last the whole duration of the battle, for she could not remember how she had been in her youth—but she could see that the enemy did not speak, and that their actions were determined\n",
            "\n",
            "High temperature (1.5) - More creative:\n",
            "In the depths of the forest where every inch of their life has fallen, it seems there still remains all the survivors\n",
            "A dark forest, covered with trees and leaves and in a dim but desolate, yet tranquil light. In its light a dark silhouette. It is an infant by day: a little brother that has vanished through time for some strange reason of course, a good brother. A great enemy; now more fully revealed in the darkness. A ghost of some past that was to strike once again\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 4: Using Top_k and Top_p\n",
        "print(\"Exercise 4: Using Top_k and Top_p\")\n",
        "prompt4 = \"The mysterious boy arrived\"\n",
        "print(f\"Prompt: {prompt4}\")\n",
        "print(\"Standard sampling (top_k=50, top_p=0.95):\")\n",
        "print(generate_text(prompt4, top_k=50, top_p=0.95))\n",
        "print(\"\\nRestricted sampling (top_k=10, top_p=0.7):\")\n",
        "print(generate_text(prompt4, top_k=10, top_p=0.7))\n",
        "print(\"\\nVery creative sampling (top_k=100, top_p=0.99):\")\n",
        "print(generate_text(prompt4, top_k=100, top_p=0.99))\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGI9lWCxM5m5",
        "outputId": "540bceef-3504-4e8c-f85d-3de68fc06ebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exercise 4: Using Top_k and Top_p\n",
            "Prompt: The mysterious boy arrived\n",
            "Standard sampling (top_k=50, top_p=0.95):\n",
            "The mysterious boy arrived with a mysterious face and an impressive arsenal of magic. In the span of the book the hero begins his quest to bring the curse of death back to the world of Azor Ahai.\n",
            "\n",
            "With only the power to remove the curse and make it permanent the hero sets out towards Azor Ahai. Written by the same author, the books will have a lasting influence on the development of the hero as well as the story that follows.\n",
            "\n",
            "HARASSAD IS\n",
            "\n",
            "Restricted sampling (top_k=10, top_p=0.7):\n",
            "The mysterious boy arrived at the scene. He had been wearing a dark cloak, and was wearing a black robe with black and white buttons. The boy was wearing a long white beard and black shoes. He was dressed in black, and was wearing a black robe with black and white buttons. The boy was dressed in black, and was wearing a black robe with black and white buttons. The boy was dressed in black, and was wearing a black robe with black and white buttons. The boy was dressed\n",
            "\n",
            "Very creative sampling (top_k=100, top_p=0.99):\n",
            "The mysterious boy arrived home looking for his missing daughter. After finding it, he ran off to find her.\n",
            "\n",
            "\n",
            "Ezra and Elisha\n",
            "\n",
            "\n",
            "\n",
            "A powerful princess and an evil prince, Ezra and Ezra are sworn to avenge a crime against the Amazons and return home, and when an elderly orphan boy named Ezra confronts them, a deadly fate looms.\n",
            "\n",
            "\n",
            "Raising Dionysius\n",
            "\n",
            "\n",
            "This drama follows Dionysius the Great, whose death heralded an\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 5: Prompt Engineering\n",
        "print(\"Exercise 5: Prompt Engineering\")\n",
        "print(\"Different prompt styles for the same concept:\")\n",
        "\n",
        "prompt5a = \"Write a story about a red car\"\n",
        "print(f\"\\nPrompt 1 (Direct): {prompt5a}\")\n",
        "print(f\"Generated: {generate_text(prompt5a, max_length=120)}\")\n",
        "\n",
        "prompt5b = \"In a land of ancient magic, a dragon guarded the mountain\"\n",
        "print(f\"\\nPrompt 2 (Descriptive): {prompt5b}\")\n",
        "print(f\"Generated: {generate_text(prompt5b, max_length=120)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkwzZq0ZYFuI",
        "outputId": "a2c851f2-0f22-4564-b3e9-35f418dcd33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exercise 5: Prompt Engineering\n",
            "Different prompt styles for the same concept:\n",
            "\n",
            "Prompt 1 (Direct): Write a story about a red car\n",
            "Generated: Write a story about a red car or white car\n",
            " You may think it's crazy to read about a red car but it is not. It is true, though. There are certain features of a car with a very distinct look and personality that are characteristic of any red car. A car with a distinctive and distinctive color is one of the most popular automobiles of all time. You may also remember the car, called the \"Buddy's wagon\" and its numerous successors, as one of the most recognizable and recognizable. There were many cars built from 1920 to 1924 that are now famous. Some were\n",
            "\n",
            "Prompt 2 (Descriptive): In a land of ancient magic, a dragon guarded the mountain\n",
            "Generated: In a land of ancient magic, a dragon guarded the mountain from an ancient horde. The dragon that guarded it could not be seen from other sides of the room. At one time, one was in the presence of a great figure, who strode into the room, and asked for help. She spoke in a voice not familiar to anyone else in the world—an unreadable question to be answered by a dragon to whom she was to speak. His voice was short and coarse, though the way in which the voice came was not difficult. In her mind it was familiar—it spoke not of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell before saving to GitHub - FIXED VERSION\n",
        "import json\n",
        "import io\n",
        "\n",
        "def clean_current_notebook():\n",
        "    try:\n",
        "        from google.colab import _message as message\n",
        "        # Get current notebook content\n",
        "        nb_content = message.blocking_request('get_ipynb', request='')['ipynb']\n",
        "\n",
        "        # Clean the metadata\n",
        "        if 'metadata' in nb_content:\n",
        "            # Remove widgets metadata completely\n",
        "            if 'widgets' in nb_content['metadata']:\n",
        "                del nb_content['metadata']['widgets']\n",
        "            # Clean colab metadata too\n",
        "            if 'colab' in nb_content['metadata'] and 'widgets' in nb_content['metadata']['colab']:\n",
        "                del nb_content['metadata']['colab']['widgets']\n",
        "\n",
        "        # Download cleaned version - FIXED DOWNLOAD\n",
        "        from google.colab import files\n",
        "\n",
        "        # Convert to JSON string\n",
        "        cleaned_content = json.dumps(nb_content, indent=2)\n",
        "\n",
        "        # Create download file - CORRECT WAY\n",
        "        with open('cleaned_notebook.ipynb', 'w') as f:\n",
        "            f.write(cleaned_content)\n",
        "\n",
        "        # Download the file\n",
        "        files.download('cleaned_notebook.ipynb')\n",
        "        print(\"✅ Cleaned notebook downloaded! Use this version for GitHub.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "clean_current_notebook()"
      ],
      "metadata": {
        "id": "f55lpyQxGsis"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}